{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING\n",
    "\n",
    "In this Jupyter Notebook the indexing of weather stations, wildfires 1992-2015 and the creation of interactive maps for California is documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libaries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the notebook on how to scrap data from NOAA API here: https://github.com/caaarov/finalproject_wildfires_CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations=pd.read_csv(\"/Users/carolinvogt/Becoming_Data_Analyst/final_project/wildfire_project/weather_stations_CA.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations.drop([\"Unnamed: 0\", \"index\"],axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4428 entries, 0 to 4427\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   station_id    4428 non-null   object \n",
      " 1   latitude      4428 non-null   float64\n",
      " 2   longitude     4428 non-null   float64\n",
      " 3   datacoverage  4428 non-null   float64\n",
      " 4   mindate       4428 non-null   object \n",
      " 5   maxdate       4428 non-null   object \n",
      " 6   min_year      4428 non-null   int64  \n",
      " 7   max_year      4428 non-null   int64  \n",
      " 8   data_period   4428 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(3)\n",
      "memory usage: 311.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_stations.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The basic functions of the H3 library are for indexing locations, which transforms latitude and longitude pairs to a 64-bit H3 index, identifying a grid cell. The function geoToH3 takes a latitude, longitude, and resolution (between 0 and 15, with 0 being coarsest and 15 being finest), and returns an index. h3ToGeo and h3ToGeoBoundary are the inverse of this function, providing the center coordinates and outline of the grid cell specified by the H3 index, respectively.\"\n",
    "\n",
    "\"Neighboring hexagons have the useful property of approximating circles using the grid system. The kRing function provides grid cells within grid distance k of an origin index.\"\n",
    "\n",
    "\"Dense hexagons representing California stand in stark contrast to compact hexagons representing the state, requiring many fewer hexagons to represent the same area.\"\n",
    "\n",
    "Source: https://eng.uber.com/h3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install h3\n",
    "#!pip install shapely\n",
    "#!pip install folium\n",
    "#!pip install os_sys \n",
    "\n",
    "import h3\n",
    "from shapely.geometry import Polygon, Point\n",
    "import shapely.wkt\n",
    "import math\n",
    "import folium\n",
    "import webbrowser #part of python standard libary\n",
    "import os\n",
    "from folium import Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Cell Areas for H3 Resolutions: https://h3geo.org/docs/core-library/restable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful function in H3 is its ability to quickly return an index’s k-nearest neighbors. This means that for k =1, a hexagon’s 1st degree neighbors are returned, and for k = 2, it is second degree neighbors (or neighbors of neighbors) and so on.\n",
    "\n",
    "https://towardsdatascience.com/uber-h3-for-data-analysis-with-python-1e54acdcc908"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest neighbours will be used for the use case of the model: Area around San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'89485b55103ffff',\n",
       " '89485b5510bffff',\n",
       " '89485b55113ffff',\n",
       " '89485b5511bffff',\n",
       " '89485b55157ffff',\n",
       " '89485b551c7ffff',\n",
       " '89485b551cfffff'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3_id = index\n",
    "h3.k_ring(h3_id,1)\n",
    "#h3.k_ring(h3_id,2)\n",
    "#h3.k_ring(h3_id,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping weather stations in CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special thanks to, would not have managed to write this code without is perfect work on UK accidents: https://github.com/joaofig/uk-accidents/blob/master/uk-accident-h3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(clusters,df):\n",
    "    # Create the map object\n",
    "    map = Map(tiles=\"cartodbpositron\", \n",
    "          attr= '© <a href=\"http://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors © <a href=\"http://cartodb.com/attributions#basemaps\">CartoDB</a>')\n",
    "\n",
    "    # Convert the clusters dictionary items to polygons and add them to the map\n",
    "    for cluster in clusters.values():\n",
    "        points = cluster['geom']\n",
    "        # points = [p[::-1] for p in points]\n",
    "        tooltip = \"{0} weather stations\".format(cluster['count'])\n",
    "        polygon = folium.vector_layers.Polygon(locations=points, tooltip=tooltip,\n",
    "                                               fill=True, \n",
    "                                               color='#1874CD', \n",
    "                                               fill_color='#1874CD', \n",
    "                                               fill_opacity=0.4, weight=3, opacity=0.4)\n",
    "        polygon.add_to(map)\n",
    "\n",
    "    # Determine the map bounding box\n",
    "    max_lat = df.latitude.max()\n",
    "    min_lat = df.latitude.min()\n",
    "    max_lon = df.longitude.max()\n",
    "    min_lon = df.longitude.min()\n",
    "    \n",
    "    # Fit the map to the bounds\n",
    "    map.fit_bounds([[min_lat, min_lon], [max_lat, max_lon]])\n",
    "    \n",
    "    return map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_map(map, file_name):\n",
    "    \"\"\"The show_map function saves the HTML generated by the map into a file and then opens a new browser tab with its contents.\"\"\"\n",
    "    map.save(file_name)\n",
    "    wb = webbrowser.open('file://' + os.path.realpath(file_name), new=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding geographical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#radians for longitude and latitude\n",
    "\n",
    "df_stations['rad_lng'] = np.radians(df_stations['longitude'].to_numpy())\n",
    "df_stations['rad_lat'] = np.radians(df_stations['latitude'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_lng_to_h3(row):\n",
    "    return h3.geo_to_h3(row['latitude'], row['longitude'], h3_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_level=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations['h3_level_4'] = df_stations.apply(lat_lng_to_h3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_level=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations['h3_level_5'] = df_stations.apply(lat_lng_to_h3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>min_year</th>\n",
       "      <th>max_year</th>\n",
       "      <th>data_period</th>\n",
       "      <th>rad_lng</th>\n",
       "      <th>rad_lat</th>\n",
       "      <th>cluster</th>\n",
       "      <th>h3_level_4</th>\n",
       "      <th>h3_level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COOP:024299</td>\n",
       "      <td>32.88333</td>\n",
       "      <td>-114.46667</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>1949-08-01</td>\n",
       "      <td>1948</td>\n",
       "      <td>1949</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.997820</td>\n",
       "      <td>0.573922</td>\n",
       "      <td>-1</td>\n",
       "      <td>84485b5ffffffff</td>\n",
       "      <td>83485bfffffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COOP:026250</td>\n",
       "      <td>34.15470</td>\n",
       "      <td>-114.29080</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>1931-01-01</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>1931</td>\n",
       "      <td>2015</td>\n",
       "      <td>84</td>\n",
       "      <td>-1.994751</td>\n",
       "      <td>0.596112</td>\n",
       "      <td>-1</td>\n",
       "      <td>8429b55ffffffff</td>\n",
       "      <td>8329b5fffffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COOP:029662</td>\n",
       "      <td>32.73333</td>\n",
       "      <td>-114.61667</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>1974-04-01</td>\n",
       "      <td>1948</td>\n",
       "      <td>1974</td>\n",
       "      <td>26</td>\n",
       "      <td>-2.000438</td>\n",
       "      <td>0.571304</td>\n",
       "      <td>0</td>\n",
       "      <td>84485bdffffffff</td>\n",
       "      <td>83485bfffffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COOP:040006</td>\n",
       "      <td>39.03333</td>\n",
       "      <td>-122.43333</td>\n",
       "      <td>0.8618</td>\n",
       "      <td>1960-08-01</td>\n",
       "      <td>1962-12-01</td>\n",
       "      <td>1960</td>\n",
       "      <td>1962</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.136865</td>\n",
       "      <td>0.681260</td>\n",
       "      <td>1</td>\n",
       "      <td>8428339ffffffff</td>\n",
       "      <td>832833fffffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COOP:040010</td>\n",
       "      <td>38.21770</td>\n",
       "      <td>-121.20130</td>\n",
       "      <td>0.9469</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>1994</td>\n",
       "      <td>2015</td>\n",
       "      <td>21</td>\n",
       "      <td>-2.115362</td>\n",
       "      <td>0.667025</td>\n",
       "      <td>1</td>\n",
       "      <td>8428329ffffffff</td>\n",
       "      <td>832836fffffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>WBAN:93242</td>\n",
       "      <td>36.98778</td>\n",
       "      <td>-120.11056</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2005</td>\n",
       "      <td>2021</td>\n",
       "      <td>16</td>\n",
       "      <td>-2.096325</td>\n",
       "      <td>0.645559</td>\n",
       "      <td>7</td>\n",
       "      <td>8429abbffffffff</td>\n",
       "      <td>8329abfffffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>WBAN:93243</td>\n",
       "      <td>37.23810</td>\n",
       "      <td>-120.88250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2004-03-25</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2004</td>\n",
       "      <td>2021</td>\n",
       "      <td>17</td>\n",
       "      <td>-2.109798</td>\n",
       "      <td>0.649927</td>\n",
       "      <td>1</td>\n",
       "      <td>8428369ffffffff</td>\n",
       "      <td>832836fffffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4425</th>\n",
       "      <td>WBAN:93244</td>\n",
       "      <td>34.60694</td>\n",
       "      <td>-120.07556</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2005-08-31</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2005</td>\n",
       "      <td>2021</td>\n",
       "      <td>16</td>\n",
       "      <td>-2.095714</td>\n",
       "      <td>0.604005</td>\n",
       "      <td>7</td>\n",
       "      <td>8429ac9ffffffff</td>\n",
       "      <td>8329acfffffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>WBAN:93245</td>\n",
       "      <td>38.32080</td>\n",
       "      <td>-123.07470</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2008-06-14</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2008</td>\n",
       "      <td>2021</td>\n",
       "      <td>13</td>\n",
       "      <td>-2.148059</td>\n",
       "      <td>0.668824</td>\n",
       "      <td>1</td>\n",
       "      <td>842831dffffffff</td>\n",
       "      <td>832831fffffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>WBAN:94299</td>\n",
       "      <td>41.49139</td>\n",
       "      <td>-120.56444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2005</td>\n",
       "      <td>2021</td>\n",
       "      <td>16</td>\n",
       "      <td>-2.104246</td>\n",
       "      <td>0.724161</td>\n",
       "      <td>5</td>\n",
       "      <td>842812bffffffff</td>\n",
       "      <td>832812fffffffff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4428 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       station_id  latitude  longitude  datacoverage     mindate     maxdate  \\\n",
       "0     COOP:024299  32.88333 -114.46667        0.9996  1948-01-01  1949-08-01   \n",
       "1     COOP:026250  34.15470 -114.29080        0.9755  1931-01-01  2015-11-01   \n",
       "2     COOP:029662  32.73333 -114.61667        0.9906  1948-01-01  1974-04-01   \n",
       "3     COOP:040006  39.03333 -122.43333        0.8618  1960-08-01  1962-12-01   \n",
       "4     COOP:040010  38.21770 -121.20130        0.9469  1994-01-01  2015-11-01   \n",
       "...           ...       ...        ...           ...         ...         ...   \n",
       "4423   WBAN:93242  36.98778 -120.11056        1.0000  2005-01-01  2021-03-04   \n",
       "4424   WBAN:93243  37.23810 -120.88250        1.0000  2004-03-25  2021-03-04   \n",
       "4425   WBAN:93244  34.60694 -120.07556        1.0000  2005-08-31  2021-03-04   \n",
       "4426   WBAN:93245  38.32080 -123.07470        1.0000  2008-06-14  2021-03-04   \n",
       "4427   WBAN:94299  41.49139 -120.56444        1.0000  2005-01-01  2021-03-04   \n",
       "\n",
       "      min_year  max_year  data_period   rad_lng   rad_lat  cluster  \\\n",
       "0         1948      1949            1 -1.997820  0.573922       -1   \n",
       "1         1931      2015           84 -1.994751  0.596112       -1   \n",
       "2         1948      1974           26 -2.000438  0.571304        0   \n",
       "3         1960      1962            2 -2.136865  0.681260        1   \n",
       "4         1994      2015           21 -2.115362  0.667025        1   \n",
       "...        ...       ...          ...       ...       ...      ...   \n",
       "4423      2005      2021           16 -2.096325  0.645559        7   \n",
       "4424      2004      2021           17 -2.109798  0.649927        1   \n",
       "4425      2005      2021           16 -2.095714  0.604005        7   \n",
       "4426      2008      2021           13 -2.148059  0.668824        1   \n",
       "4427      2005      2021           16 -2.104246  0.724161        5   \n",
       "\n",
       "           h3_level_4       h3_level_3  \n",
       "0     84485b5ffffffff  83485bfffffffff  \n",
       "1     8429b55ffffffff  8329b5fffffffff  \n",
       "2     84485bdffffffff  83485bfffffffff  \n",
       "3     8428339ffffffff  832833fffffffff  \n",
       "4     8428329ffffffff  832836fffffffff  \n",
       "...               ...              ...  \n",
       "4423  8429abbffffffff  8329abfffffffff  \n",
       "4424  8428369ffffffff  832836fffffffff  \n",
       "4425  8429ac9ffffffff  8329acfffffffff  \n",
       "4426  842831dffffffff  832831fffffffff  \n",
       "4427  842812bffffffff  832812fffffffff  \n",
       "\n",
       "[4428 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4427"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(df_stations[\"station_id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(df_stations['h3_level_3'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(df_stations['h3_level_4'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully saved\n"
     ]
    }
   ],
   "source": [
    "#df_stations.to_csv(\"/Users/carolinvogt/Becoming_Data_Analyst/final_project/wildfire_project/CA_weather_stations_clustered_4.csv\")\n",
    "\n",
    "print(\"Sucessfully saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "233 vs 1888 (h3_level=4 vs h3_level=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_weather = dict()\n",
    "\n",
    "for index, row in df_stations.iterrows():\n",
    "    key = row['h3_level_4']\n",
    "    #print(key)\n",
    "    if key in clusters_weather:\n",
    "        clusters_weather[key]['count'] += 1\n",
    "    else:\n",
    "        clusters_weather[key] = {\"count\": 1,\n",
    "                         \"geom\": h3.h3_to_geo_boundary(key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters_weather)\n",
    "#len(list(df_stations['h3'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = create_map(clusters_weather,df_stations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h3_level=6\n",
    "show_map(map, \"map_{0}.html\".format(h3_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping wildfires in CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wildfires=pd.read_csv(\"/Users/carolinvogt/Becoming_Data_Analyst/final_project/wildfire_project/big_wildfires_CA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wildfires.drop([\"Unnamed: 0\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns=[]\n",
    "for col in list(df_wildfires.columns):\n",
    "    new_columns.append(col.lower())\n",
    "    \n",
    "df_wildfires.columns=new_columns\n",
    "#df_wildfires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#radians for longitude and latitude\n",
    "\n",
    "df_wildfires['rad_lng'] = np.radians(df_wildfires['longitude'].to_numpy())\n",
    "df_wildfires['rad_lat'] = np.radians(df_wildfires['latitude'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_level=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wildfires['h3_level_5'] = df_wildfires.apply(lat_lng_to_h3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_level=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wildfires['h3_level_3'] = df_wildfires.apply(lat_lng_to_h3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_level=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wildfires['h3_level_6'] = df_wildfires.apply(lat_lng_to_h3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1293"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(df_wildfires['h3_level_5'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully saved\n"
     ]
    }
   ],
   "source": [
    "df_wildfires.to_csv(\"/Users/carolinvogt/Becoming_Data_Analyst/final_project/wildfire_project/CA_wildfires_clustered.csv\")\n",
    "\n",
    "print(\"Sucessfully saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_fire = dict()\n",
    "\n",
    "for index, row in df_wildfires.iterrows():\n",
    "    key = row['h3_level_6']\n",
    "    #print(key)\n",
    "    if key in clusters_fire:\n",
    "        clusters_fire[key]['count'] += 1\n",
    "    else:\n",
    "        clusters_fire[key] = {\"count\": 1,\n",
    "                         \"geom\": h3.h3_to_geo_boundary(key)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map_fire(clusters,df):\n",
    "    # Create the map object\n",
    "    map = Map(tiles=\"cartodbpositron\", \n",
    "          attr= '© <a href=\"http://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors © <a href=\"http://cartodb.com/attributions#basemaps\">CartoDB</a>')\n",
    "\n",
    "    # Convert the clusters dictionary items to polygons and add them to the map\n",
    "    for cluster in clusters.values():\n",
    "        points = cluster['geom']\n",
    "        # points = [p[::-1] for p in points]\n",
    "        tooltip = \"{0} fire\".format(cluster['count'])\n",
    "        polygon = folium.vector_layers.Polygon(locations=points, tooltip=tooltip,\n",
    "                                               fill=True, \n",
    "                                               color='#ff0000', \n",
    "                                               fill_color='#ff0000', \n",
    "                                               fill_opacity=0.4, weight=3, opacity=0.4)\n",
    "        polygon.add_to(map)\n",
    "\n",
    "    # Determine the map bounding box\n",
    "    max_lat = df.latitude.max()\n",
    "    min_lat = df.latitude.min()\n",
    "    max_lon = df.longitude.max()\n",
    "    min_lon = df.longitude.min()\n",
    "    \n",
    "    # Fit the map to the bounds\n",
    "    map.fit_bounds([[min_lat, min_lon], [max_lat, max_lon]])\n",
    "    \n",
    "    return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = create_map_fire(clusters_fire,df_wildfires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_level=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_map(map, \"map_{0}.html\".format(h3_level))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
